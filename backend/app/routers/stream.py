"""
Ø±ÙˆØªØ± Ø§Ù„Ø¨Ø« - Stream Router
==========================
GET /api/v1/stream/{camera_id} - Ø¨Ø« Ø§Ù„ÙÙŠØ¯ÙŠÙˆ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬
GET /api/v1/stream/{camera_id}/snapshot - Ù„Ù‚Ø·Ø© Ø­Ø§Ù„ÙŠØ©
"""

from fastapi import APIRouter, Depends, HTTPException, status
from fastapi.responses import StreamingResponse, Response
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select
from typing import AsyncGenerator, Dict, Optional, Tuple
from pathlib import Path
from datetime import datetime
import logging
import asyncio
import io
import cv2
import numpy as np
from concurrent.futures import ThreadPoolExecutor
import time
import uuid

from app.database import get_db, AsyncSessionLocal
from app.models.camera import Camera
from app.models.alert import Alert, AlertStatus, AlertSeverity, WeaponType
from app.models.incident import Incident, IncidentStatus
from app.services.detector import detector
from app.config import settings
from app.services.notification import NotificationService

# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø³Ø¬Ù„
logger = logging.getLogger("nazra.stream")

# =====================================
# Alert System for Simulation
# =====================================
# Rate limiting: last alert time per camera_id
_simulation_alert_cooldown: Dict[str, float] = {}
_simulation_alert_count: Dict[str, int] = {}  # Track alert count per camera
SIMULATION_ALERT_INTERVAL = 60.0  # Minimum 60 seconds between alerts for same camera
MAX_ALERTS_PER_CAMERA = 5  # Maximum alerts per camera before requiring manual reset

# Notification service instance
_notification_service: Optional[NotificationService] = None

def get_notification_service() -> NotificationService:
    """Get or create notification service singleton"""
    global _notification_service
    if _notification_service is None:
        _notification_service = NotificationService()
    return _notification_service


# Map English class names to Arabic weapon types
CLASS_NAME_TO_WEAPON_TYPE = {
    'knife': WeaponType.KNIFE.value,
    'Knife': WeaponType.KNIFE.value,
    'handgun': WeaponType.PISTOL.value,
    'Handgun': WeaponType.PISTOL.value,
    'pistol': WeaponType.PISTOL.value,
    'Pistol': WeaponType.PISTOL.value,
    'rifle': WeaponType.RIFLE.value,
    'Rifle': WeaponType.RIFLE.value,
    'gun': WeaponType.PISTOL.value,
    'Gun': WeaponType.PISTOL.value,
}


async def ensure_simulation_camera_exists(camera_id: str, camera_name: str, location: str) -> bool:
    """
    Ensure a simulation camera record exists in the database (for FK constraint)
    """
    from sqlalchemy import select
    
    # Sanitize camera_id for DB
    db_camera_id = camera_id.replace(":", "_")
    
    try:
        async with AsyncSessionLocal() as db:
            # Check if camera exists
            result = await db.execute(
                select(Camera).where(Camera.id == db_camera_id)
            )
            existing = result.scalar_one_or_none()
            
            if not existing:
                # Create simulation camera
                sim_camera = Camera(
                    id=db_camera_id,
                    name=camera_name,
                    location=location,
                    rtsp_url=f"simulation://{camera_id}",
                    status="online",
                    detection_enabled=True,
                )
                db.add(sim_camera)
                await db.commit()
                logger.info(f"ğŸ“¹ Created simulation camera in DB: {db_camera_id}")
            
            return True
    except Exception as e:
        logger.warning(f"Could not ensure simulation camera exists: {e}")
        return False


async def get_or_create_incident(
    db: AsyncSession,
    camera_id: str,
    camera_name: str,
    location: str,
    weapon_type: str,
    severity: str
) -> Tuple[Incident, bool]:
    """
    Ø¬Ù„Ø¨ Ø­Ø§Ø¯Ø«Ø© Ù†Ø´Ø·Ø© Ù…ÙˆØ¬ÙˆØ¯Ø© Ø£Ùˆ Ø¥Ù†Ø´Ø§Ø¡ ÙˆØ§Ø­Ø¯Ø© Ø¬Ø¯ÙŠØ¯Ø©
    
    Returns: (incident, is_new)
    """
    from datetime import timedelta
    
    INCIDENT_TIMEOUT_MINUTES = 5  # 5 minutes timeout
    timeout_threshold = datetime.utcnow() - timedelta(minutes=INCIDENT_TIMEOUT_MINUTES)
    
    # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø­Ø§Ø¯Ø«Ø© Ù†Ø´Ø·Ø© Ù…ÙˆØ¬ÙˆØ¯Ø©
    result = await db.execute(
        select(Incident).where(
            Incident.camera_id == camera_id,
            Incident.primary_weapon_type == weapon_type,
            Incident.status == IncidentStatus.ACTIVE.value,
            Incident.last_detection_at >= timeout_threshold
        )
    )
    existing_incident = result.scalar_one_or_none()
    
    if existing_incident:
        return existing_incident, False
    
    # Ø¥Ù†Ø´Ø§Ø¡ Ø­Ø§Ø¯Ø«Ø© Ø¬Ø¯ÙŠØ¯Ø©
    new_incident = Incident(
        camera_id=camera_id,
        camera_name=camera_name,
        location=location,
        primary_weapon_type=weapon_type,
        severity=severity,
        status=IncidentStatus.ACTIVE.value,
    )
    db.add(new_incident)
    await db.flush()  # Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ ID
    
    return new_incident, True


async def create_simulation_alert(
    camera_id: str,
    camera_name: str,
    location: str,
    detection: dict,
    frame: np.ndarray,
) -> Optional[str]:
    """
    ğŸš¨ Create an alert from simulation detection with Incident grouping
    
    - Groups alerts into incidents (same camera + weapon type + time window)
    - Only broadcasts WebSocket notification for NEW incidents
    - Reduces spam significantly while maintaining all data
    
    Returns alert_id if created, None if skipped
    """
    global _simulation_alert_cooldown, _simulation_alert_count
    
    current_time = time.time()
    
    # Check if max alerts reached for this camera (per session)
    alert_count = _simulation_alert_count.get(camera_id, 0)
    if alert_count >= MAX_ALERTS_PER_CAMERA:
        if alert_count == MAX_ALERTS_PER_CAMERA:
            logger.info(f"â¸ï¸ Max alerts ({MAX_ALERTS_PER_CAMERA}) reached for {camera_id}")
            _simulation_alert_count[camera_id] = alert_count + 1
        return None
    
    # Check cooldown between alerts (reduced from 60s to 10s since we group into incidents)
    last_alert_time = _simulation_alert_cooldown.get(camera_id, 0)
    if current_time - last_alert_time < 10.0:  # 10 seconds between individual alerts
        return None
    
    _simulation_alert_cooldown[camera_id] = current_time
    _simulation_alert_count[camera_id] = alert_count + 1
    
    try:
        # Ensure simulation camera exists in DB
        await ensure_simulation_camera_exists(camera_id, camera_name, location)
        
        # Extract detection info
        class_name = detection.get('class_name', 'unknown')
        confidence = detection.get('confidence', 0.0)
        bbox = detection.get('bbox', (0, 0, 0, 0))
        
        # Map to Arabic weapon type
        weapon_type = CLASS_NAME_TO_WEAPON_TYPE.get(class_name, WeaponType.OTHER.value)
        severity = Alert.get_severity_from_weapon(weapon_type)
        
        # Generate alert ID
        alert_id = str(uuid.uuid4())
        sanitized_camera_id = camera_id.replace(":", "_")
        
        # Save snapshot
        snapshot_dir = Path(settings.ALERTS_DIR if hasattr(settings, 'ALERTS_DIR') else 'alerts')
        snapshot_dir.mkdir(parents=True, exist_ok=True)
        snapshot_filename = f"alert_{alert_id}.jpg"
        snapshot_path = snapshot_dir / snapshot_filename
        
        # Draw detection on snapshot
        frame_copy = frame.copy()
        x1, y1, x2, y2 = bbox
        cv2.rectangle(frame_copy, (x1, y1), (x2, y2), (0, 0, 255), 3)
        cv2.putText(frame_copy, f"{class_name}: {confidence:.0%}", (x1, y1 - 10),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)
        
        cv2.imwrite(str(snapshot_path), frame_copy)
        
        # Create alert and incident in database
        async with AsyncSessionLocal() as db:
            # Get or create incident
            incident, is_new_incident = await get_or_create_incident(
                db=db,
                camera_id=sanitized_camera_id,
                camera_name=camera_name,
                location=location,
                weapon_type=weapon_type,
                severity=severity
            )
            
            # Create alert linked to incident
            alert = Alert(
                id=alert_id,
                incident_id=incident.id,
                camera_id=sanitized_camera_id,
                camera_name=camera_name,
                location=location,
                weapon_type=weapon_type,
                confidence=confidence,
                severity=severity,
                image_snapshot=str(snapshot_path),
                bounding_box={
                    'x': int(x1),
                    'y': int(y1),
                    'width': int(x2 - x1),
                    'height': int(y2 - y1)
                },
                status=AlertStatus.NEW.value,
            )
            db.add(alert)
            
            # Update incident statistics
            incident.alert_count += 1
            incident.detection_count += 1
            incident.last_detection_at = datetime.utcnow()
            
            # Update max confidence and best snapshot
            if confidence > incident.max_confidence:
                incident.max_confidence = confidence
                incident.best_snapshot = str(snapshot_path)
            
            # Update average confidence
            if incident.avg_confidence == 0:
                incident.avg_confidence = confidence
            else:
                incident.avg_confidence = (
                    (incident.avg_confidence * (incident.detection_count - 1) + confidence) 
                    / incident.detection_count
                )
            
            await db.commit()
            
            incident_id = incident.id
            incident_alert_count = incident.alert_count
            
            if is_new_incident:
                logger.info(f"ğŸ†• New incident created: {incident_id} for {camera_name}")
            
            logger.info(f"ğŸš¨ Alert {alert_id} added to incident {incident_id} (count: {incident_alert_count})")
        
        # Send WebSocket notification ONLY for new incidents or significant updates
        # This drastically reduces spam!
        should_broadcast = is_new_incident or (incident_alert_count % 10 == 0)  # Every 10 alerts
        
        if should_broadcast:
            try:
                from app.routers.websocket import manager
                await manager.broadcast_alert({
                    "type": "incident_update" if not is_new_incident else "new_incident",
                    "incident_id": incident_id,
                    "alert_id": alert_id,
                    "camera_id": camera_id,
                    "camera_name": camera_name,
                    "location": location,
                    "weapon_type": weapon_type,
                    "class_name": class_name,
                    "confidence": confidence,
                    "severity": severity,
                    "alert_count": incident_alert_count,
                    "is_new_incident": is_new_incident,
                    "image_snapshot": f"/alerts/{snapshot_filename}",
                    "bbox": {
                        "x1": int(x1),
                        "y1": int(y1),
                        "x2": int(x2),
                        "y2": int(y2)
                    },
                    "timestamp": datetime.utcnow().isoformat()
                })
                logger.info(f"ğŸ“¡ {'New incident' if is_new_incident else 'Incident update'} broadcast: {incident_id}")
            except Exception as ws_err:
                logger.warning(f"WebSocket broadcast failed: {ws_err}")
        
        # Send security notification ONLY for new incidents
        if is_new_incident:
            try:
                notification_service = get_notification_service()
                await notification_service.send_alert_notification(
                    alert_id=alert_id,
                    camera_name=camera_name,
                    weapon_type=weapon_type,
                    location=location,
                    confidence=confidence,
                    image_url=f"/alerts/{snapshot_filename}"
                )
                logger.info(f"ğŸ”” Security notification sent for new incident")
            except Exception as notif_err:
                logger.warning(f"Notification failed: {notif_err}")
        
        return alert_id
        
    except Exception as e:
        logger.error(f"âŒ Failed to create simulation alert: {e}")
        import traceback
        traceback.print_exc()
        return None

# âš¡ TurboJPEG Ù„Ù„ØªØ±Ù…ÙŠØ² Ø§Ù„Ø³Ø±ÙŠØ¹ (3x Ø£Ø³Ø±Ø¹ Ù…Ù† OpenCV)
try:
    from turbojpeg import TurboJPEG
    _turbo_jpeg = TurboJPEG()
    TURBOJPEG_AVAILABLE = True
    logger.info("TurboJPEG available - 3x faster encoding")
except ImportError:
    _turbo_jpeg = None
    TURBOJPEG_AVAILABLE = False

def fast_encode_jpeg(frame: np.ndarray, quality: int = 70) -> bytes:
    """
    âš¡ ØªØ±Ù…ÙŠØ² JPEG Ø³Ø±ÙŠØ¹
    ÙŠØ³ØªØ®Ø¯Ù… TurboJPEG Ø¥Ø°Ø§ Ù…ØªÙˆÙØ± (3x Ø£Ø³Ø±Ø¹)
    """
    if TURBOJPEG_AVAILABLE and _turbo_jpeg:
        return _turbo_jpeg.encode(frame, quality=quality)
    else:
        encode_param = [int(cv2.IMWRITE_JPEG_QUALITY), quality]
        _, buffer = cv2.imencode('.jpg', frame, encode_param)
        return buffer.tobytes()

router = APIRouter(prefix="/stream", tags=["Ø§Ù„Ø¨Ø«"])

# ØªØ®Ø²ÙŠÙ† Ø§ØªØµØ§Ù„Ø§Øª Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§Øª Ø§Ù„Ù†Ø´Ø·Ø©
active_captures: Dict[str, cv2.VideoCapture] = {}
capture_locks: Dict[str, asyncio.Lock] = {}
# âš¡ ThreadPoolExecutor Ù…Ø­Ø³Ù‘Ù† Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª
executor = ThreadPoolExecutor(max_workers=settings.MAX_CONCURRENT_STREAMS)

# âš¡ Motion Detection Cache - Ù„ØªØ®Ø·ÙŠ Ø§Ù„Ø¥Ø·Ø§Ø±Ø§Øª Ø§Ù„Ø«Ø§Ø¨ØªØ©
_motion_cache: Dict[str, np.ndarray] = {}  # camera_id -> previous_gray_frame
_frame_cache: Dict[str, Tuple[bytes, float]] = {}  # camera_id -> (encoded_frame, timestamp)
_last_cleanup: float = 0.0  # ÙˆÙ‚Øª Ø¢Ø®Ø± ØªÙ†Ø¸ÙŠÙ
FRAME_CACHE_TTL = 0.1  # 100ms cache
CACHE_CLEANUP_INTERVAL = 60.0  # ØªÙ†Ø¸ÙŠÙ Ø§Ù„ÙƒØ§Ø´ ÙƒÙ„ 60 Ø«Ø§Ù†ÙŠØ©

def cleanup_stale_caches():
    """
    ğŸ§¹ ØªÙ†Ø¸ÙŠÙ Ø§Ù„ÙƒØ§Ø´ Ø§Ù„Ù‚Ø¯ÙŠÙ… - ÙŠÙ…Ù†Ø¹ ØªØ³Ø±Ø¨ Ø§Ù„Ø°Ø§ÙƒØ±Ø©
    ÙŠÙÙ†ÙØ° ÙƒÙ„ 60 Ø«Ø§Ù†ÙŠØ©
    """
    global _motion_cache, _frame_cache, _last_cleanup
    current_time = time.time()
    
    if current_time - _last_cleanup < CACHE_CLEANUP_INTERVAL:
        return
    
    _last_cleanup = current_time
    
    # ØªÙ†Ø¸ÙŠÙ frame cache Ø§Ù„Ù‚Ø¯ÙŠÙ…
    stale_cameras = [
        cam_id for cam_id, (_, timestamp) in _frame_cache.items()
        if current_time - timestamp > 30.0  # 30 Ø«Ø§Ù†ÙŠØ©
    ]
    for cam_id in stale_cameras:
        _frame_cache.pop(cam_id, None)
        _motion_cache.pop(cam_id, None)
    
    if stale_cameras:
        logger.debug(f"Cleaned {len(stale_cameras)} cameras from cache")

def detect_motion(camera_id: str, frame: np.ndarray, threshold: float = 0.02) -> bool:
    """
    ğŸ¯ Motion Detection - Ø§ÙƒØªØ´Ø§Ù Ø§Ù„Ø­Ø±ÙƒØ©
    ====================================
    ÙŠÙØ³ØªØ®Ø¯Ù… Ù„ØªØ®Ø·ÙŠ Ø§Ù„ÙƒØ´Ù AI Ø¹Ù„Ù‰ Ø§Ù„Ø¥Ø·Ø§Ø±Ø§Øª Ø§Ù„Ø«Ø§Ø¨ØªØ©
    ÙŠÙˆÙØ± ~70% Ù…Ù† Ù…Ø¹Ø§Ù„Ø¬Ø© AI Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø´Ø§Ù‡Ø¯ Ø§Ù„Ù‡Ø§Ø¯Ø¦Ø©
    
    Returns:
        True Ø¥Ø°Ø§ ÙƒØ§Ù† Ù‡Ù†Ø§Ùƒ Ø­Ø±ÙƒØ© ÙƒØ§ÙÙŠØ©
    """
    global _motion_cache
    
    # ØªØ­ÙˆÙŠÙ„ Ù„Ù€ grayscale ÙˆØªØµØºÙŠØ±
    small = cv2.resize(frame, (160, 120))
    gray = cv2.cvtColor(small, cv2.COLOR_BGR2GRAY)
    gray = cv2.GaussianBlur(gray, (5, 5), 0)
    
    # Ù…Ù‚Ø§Ø±Ù†Ø© Ù…Ø¹ Ø§Ù„Ø¥Ø·Ø§Ø± Ø§Ù„Ø³Ø§Ø¨Ù‚
    if camera_id not in _motion_cache:
        _motion_cache[camera_id] = gray
        return True  # Ø£ÙˆÙ„ Ø¥Ø·Ø§Ø± - Ø¯Ø§Ø¦Ù…Ø§Ù‹ Ù…Ø¹Ø§Ù„Ø¬Ø©
    
    prev_gray = _motion_cache[camera_id]
    
    # Ø­Ø³Ø§Ø¨ Ø§Ù„ÙØ±Ù‚
    diff = cv2.absdiff(prev_gray, gray)
    _, thresh = cv2.threshold(diff, 25, 255, cv2.THRESH_BINARY)
    
    # Ù†Ø³Ø¨Ø© Ø§Ù„Ø¨ÙƒØ³Ù„Ø§Øª Ø§Ù„Ù…ØªØºÙŠØ±Ø©
    change_ratio = np.sum(thresh > 0) / thresh.size
    
    # ØªØ­Ø¯ÙŠØ« Ø§Ù„ÙƒØ§Ø´
    _motion_cache[camera_id] = gray
    
    return change_ratio > threshold

# Ø£Ù„ÙˆØ§Ù† Ù…Ø±Ø¨Ø¹Ø§Øª Ø§Ù„ÙƒØ´Ù
DETECTION_COLORS = {
    'Knife': (0, 165, 255),      # Ø¨Ø±ØªÙ‚Ø§Ù„ÙŠ
    'Handgun': (0, 0, 255),      # Ø£Ø­Ù…Ø±
    'weapon': (0, 0, 255),       # Ø£Ø­Ù…Ø±
    'knife': (0, 165, 255),      # Ø¨Ø±ØªÙ‚Ø§Ù„ÙŠ
}


def draw_detections_on_frame(frame: np.ndarray, detections: list) -> np.ndarray:
    """
    Ø±Ø³Ù… Ù…Ø±Ø¨Ø¹Ø§Øª Ø§Ù„ÙƒØ´Ù Ø¹Ù„Ù‰ Ø§Ù„Ø¥Ø·Ø§Ø±
    """
    for det in detections:
        x1, y1, x2, y2 = det['bbox']
        class_name = det['class_name']
        confidence = det['confidence']
        
        # Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ù„ÙˆÙ†
        color = DETECTION_COLORS.get(class_name, (0, 0, 255))
        
        # Ø±Ø³Ù… Ø§Ù„Ù…Ø±Ø¨Ø¹
        cv2.rectangle(frame, (x1, y1), (x2, y2), color, 3)
        
        # Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù†Øµ
        label = f"{class_name}: {confidence:.0%}"
        font = cv2.FONT_HERSHEY_SIMPLEX
        font_scale = 0.7
        thickness = 2
        
        # Ø­Ø³Ø§Ø¨ Ø­Ø¬Ù… Ø§Ù„Ù†Øµ
        (text_width, text_height), baseline = cv2.getTextSize(label, font, font_scale, thickness)
        
        # Ø±Ø³Ù… Ø®Ù„ÙÙŠØ© Ø§Ù„Ù†Øµ
        cv2.rectangle(frame, (x1, y1 - text_height - 10), (x1 + text_width + 10, y1), color, -1)
        
        # Ø±Ø³Ù… Ø§Ù„Ù†Øµ
        cv2.putText(frame, label, (x1 + 5, y1 - 5), font, font_scale, (255, 255, 255), thickness)
        
        # Ø±Ø³Ù… Ø²ÙˆØ§ÙŠØ§ Ù…Ù…ÙŠØ²Ø©
        corner_len = 20
        cv2.line(frame, (x1, y1), (x1 + corner_len, y1), color, 4)
        cv2.line(frame, (x1, y1), (x1, y1 + corner_len), color, 4)
        cv2.line(frame, (x2, y1), (x2 - corner_len, y1), color, 4)
        cv2.line(frame, (x2, y1), (x2, y1 + corner_len), color, 4)
        cv2.line(frame, (x1, y2), (x1 + corner_len, y2), color, 4)
        cv2.line(frame, (x1, y2), (x1, y2 - corner_len), color, 4)
        cv2.line(frame, (x2, y2), (x2 - corner_len, y2), color, 4)
        cv2.line(frame, (x2, y2), (x2, y2 - corner_len), color, 4)
    
    return frame


def process_frame_with_detection(cap: cv2.VideoCapture, detect: bool = True, last_detections: list = None, camera_id: str = "unknown") -> Tuple[Optional[bytes], list]:
    """
    Ù‚Ø±Ø§Ø¡Ø© Ø¥Ø·Ø§Ø± Ù…Ù† Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§ ÙˆØªØ´ØºÙŠÙ„ Ø§Ù„ÙƒØ´Ù Ø¹Ù„ÙŠÙ‡
    
    âš¡ Ù…Ø­Ø³Ù‘Ù† Ù…Ø¹:
    - Motion Detection Ù„ØªØ®Ø·ÙŠ Ø§Ù„Ù…Ø´Ø§Ù‡Ø¯ Ø§Ù„Ø«Ø§Ø¨ØªØ©
    - Frame Cache Ù„Ù„Ù…Ø´ØªØ±ÙƒÙŠÙ† Ø§Ù„Ù…ØªØ¹Ø¯Ø¯ÙŠÙ†
    """
    detections = last_detections or []
    try:
        # ØªØ®Ø·ÙŠ Ø§Ù„Ø¥Ø·Ø§Ø±Ø§Øª Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø© ÙÙŠ Ø§Ù„Ø¨ÙˆÙØ± Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø£Ø­Ø¯Ø« Ø¥Ø·Ø§Ø±
        # ØªØ®Ø·ÙŠ Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠ: Ø­Ø¯ Ø£Ù‚ØµÙ‰ 5 Ø¥Ø·Ø§Ø±Ø§Øª Ù„ØªØ¬Ù†Ø¨ Ø§Ù„Ù‡Ø¯Ø±
        buffer_size = int(cap.get(cv2.CAP_PROP_BUFFERSIZE)) or 5
        for _ in range(min(buffer_size, 5)):
            cap.grab()
        
        ret, frame = cap.read()
        if not ret or frame is None:
            return None, detections
        
        # ØªØµØºÙŠØ± Ø§Ù„Ø¥Ø·Ø§Ø± Ù„ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø£Ø¯Ø§Ø¡
        height, width = frame.shape[:2]
        max_width = 640
        if width > max_width:
            scale = max_width / width
            frame = cv2.resize(frame, None, fx=scale, fy=scale)
        
        # âš¡ Motion Detection - ØªØ®Ø·ÙŠ AI Ø¥Ø°Ø§ Ù„Ù… ØªÙƒÙ† Ù‡Ù†Ø§Ùƒ Ø­Ø±ÙƒØ©
        has_motion = True
        if detect:
            has_motion = detect_motion(camera_id, frame, threshold=0.02)
            if not has_motion and last_detections:
                # Ù„Ø§ Ø­Ø±ÙƒØ© + ÙŠÙˆØ¬Ø¯ ÙƒØ´ÙˆÙØ§Øª Ø³Ø§Ø¨Ù‚Ø© = Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©
                detect = False
        
        # ØªØ´ØºÙŠÙ„ Ø§Ù„ÙƒØ´Ù Ø¥Ø°Ø§ ÙƒØ§Ù† Ù…ÙØ¹Ù„Ø§Ù‹ ÙˆÙ‡Ù†Ø§Ùƒ Ø­Ø±ÙƒØ©
        if detect and has_motion and detector.is_loaded:
            try:
                # Ù…Ø³Ø­ Ø§Ù„ÙƒØ´ÙˆÙØ§Øª Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø© Ø¹Ù†Ø¯ Ø§Ù„ÙƒØ´Ù Ø§Ù„Ø¬Ø¯ÙŠØ¯
                detections = []
                results = detector.model(
                    frame,
                    conf=detector.confidence_threshold,
                    device=detector.device,
                    verbose=False
                )
                
                for result in results:
                    boxes = result.boxes
                    if boxes is None or len(boxes) == 0:
                        continue
                    
                    # âš¡ Batch GPUâ†’CPU Transfer - Ø£Ø³Ø±Ø¹ 15%
                    all_xyxy = boxes.xyxy.cpu().numpy()
                    all_conf = boxes.conf.cpu().numpy()
                    all_cls = boxes.cls.cpu().numpy().astype(int)
                    
                    for i in range(len(boxes)):
                        x1, y1, x2, y2 = all_xyxy[i]
                        confidence = float(all_conf[i])
                        class_id = int(all_cls[i])
                        class_name = detector.model.names[class_id]
                        
                        detections.append({
                            'class_name': class_name,
                            'confidence': confidence,
                            'bbox': (int(x1), int(y1), int(x2), int(y2))
                        })
                    
            except Exception as e:
                logger.error(f"Detection error: {e}")
        
        # Ø±Ø³Ù… Ø§Ù„Ù…Ø±Ø¨Ø¹Ø§Øª Ø¹Ù„Ù‰ Ø§Ù„Ø¥Ø·Ø§Ø± (Ù…Ù† Ø§Ù„ÙƒØ´Ù Ø§Ù„Ø­Ø§Ù„ÙŠ Ø£Ùˆ Ø§Ù„Ø³Ø§Ø¨Ù‚)
        if detections:
            frame = draw_detections_on_frame(frame, detections)
        
        # âš¡ ØªÙ†Ø¸ÙŠÙ Ø§Ù„ÙƒØ§Ø´ Ø¯ÙˆØ±ÙŠØ§Ù‹ (Ù„Ù…Ù†Ø¹ ØªØ³Ø±Ø¨ Ø§Ù„Ø°Ø§ÙƒØ±Ø©)
        cleanup_stale_caches()
        
        # âš¡ ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ JPEG - Ø§Ø³ØªØ®Ø¯Ø§Ù… TurboJPEG Ø¥Ø°Ø§ Ù…ØªÙˆÙØ±
        return fast_encode_jpeg(frame, settings.JPEG_QUALITY_STREAM), detections
        
    except Exception as e:
        logger.error(f"Frame processing error: {e}")
        return None, []


async def generate_video_frames_with_detection(
    camera_id: str, 
    rtsp_url: str,
    detection_enabled: bool = True
) -> AsyncGenerator[bytes, None]:
    """
    Ù…ÙˆÙ„Ø¯ Ø¥Ø·Ø§Ø±Ø§Øª Ø§Ù„ÙÙŠØ¯ÙŠÙˆ Ù…Ù† RTSP Ù…Ø¹ Ø§Ù„ÙƒØ´Ù Ø¹Ù† Ø§Ù„Ø£Ø³Ù„Ø­Ø©
    
    ÙŠÙØ±Ø¬Ø¹ Ø¥Ø·Ø§Ø±Ø§Øª MJPEG Ù„Ù„Ø¨Ø« Ù…Ø¹ Ù…Ø±Ø¨Ø¹Ø§Øª Ø§Ù„ÙƒØ´Ù
    """
    cap = None
    frame_count = 0
    detection_interval = 5  # ØªØ´ØºÙŠÙ„ Ø§Ù„ÙƒØ´Ù ÙƒÙ„ 5 Ø¥Ø·Ø§Ø±Ø§Øª Ù„Ù„Ø³Ø±Ø¹Ø©
    last_detections = []
    
    try:
        logger.info(f"Opening stream: {rtsp_url}")
        
        # Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª RTSP Ù„ØªÙ‚Ù„ÙŠÙ„ Ø§Ù„ØªØ£Ø®ÙŠØ±
        import os
        os.environ['OPENCV_FFMPEG_CAPTURE_OPTIONS'] = 'rtsp_transport;udp|fflags;nobuffer|flags;low_delay|framedrop;1'
        
        # ÙØªØ­ Ø§ØªØµØ§Ù„ OpenCV Ù…Ø¹ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ù…Ø­Ø³Ù†Ø© Ù„Ù„Ø³Ø±Ø¹Ø©
        cap = cv2.VideoCapture(rtsp_url, cv2.CAP_FFMPEG)
        cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)  # Ø£Ù‚Ù„ buffer Ù…Ù…ÙƒÙ†
        cap.set(cv2.CAP_PROP_FPS, 15)  # 15 FPS
        
        if not cap.isOpened():
            logger.error(f"Failed to open stream: {rtsp_url}")
            return
        
        logger.info(f"Connected to camera: {camera_id} - Detection: {'ON' if detection_enabled else 'OFF'}")
        
        max_consecutive_failures = 10
        consecutive_failures = 0
        
        loop = asyncio.get_event_loop()
        
        while consecutive_failures < max_consecutive_failures:
            try:
                # ØªØ­Ø¯ÙŠØ¯ Ù…Ø§ Ø¥Ø°Ø§ ÙƒØ§Ù† ÙŠØ¬Ø¨ ØªØ´ØºÙŠÙ„ Ø§Ù„ÙƒØ´Ù ÙÙŠ Ù‡Ø°Ø§ Ø§Ù„Ø¥Ø·Ø§Ø±
                should_detect = detection_enabled and (frame_count % detection_interval == 0)
                
                # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¥Ø·Ø§Ø± Ù…Ø¹ camera_id Ù„Ù„Ù€ motion detection
                frame_bytes, detections = await loop.run_in_executor(
                    executor, 
                    process_frame_with_detection, 
                    cap, 
                    should_detect,
                    last_detections,
                    camera_id
                )
                
                if frame_bytes is None:
                    consecutive_failures += 1
                    await asyncio.sleep(0.05)
                    continue
                
                consecutive_failures = 0
                frame_count += 1
                
                # ØªØ­Ø¯ÙŠØ« Ø¢Ø®Ø± Ø§Ù„ÙƒØ´ÙˆÙØ§Øª
                if detections:
                    last_detections = detections
                    if should_detect:
                        logger.info(f"Detected {len(detections)} threat(s) in camera: {camera_id}")
                
                # Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ø¥Ø·Ø§Ø±
                yield (
                    b'--frame\r\n'
                    b'Content-Type: image/jpeg\r\n\r\n' + 
                    frame_bytes + 
                    b'\r\n'
                )
                
                # âš¡ Dynamic FPS Control - ØªØ­ÙƒÙ… Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ ÙˆÙ‚Øª Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©
                # Ù‡Ø¯Ù: 15 FPS = 66ms per frame
                target_interval = 0.066
                # Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„ÙƒØ´Ù Ù…ÙØ¹Ù„ØŒ Ø²Ø¯ Ø§Ù„ÙØ§ØµÙ„ Ù‚Ù„ÙŠÙ„Ø§Ù‹ Ù„Ù„Ø§Ø³ØªÙ‚Ø±Ø§Ø±
                if should_detect and detections:
                    target_interval = 0.08  # ~12 FPS Ø¹Ù†Ø¯ Ø§Ù„ÙƒØ´Ù Ø§Ù„Ù†Ø´Ø·
                await asyncio.sleep(target_interval)
                
            except asyncio.CancelledError:
                logger.info(f"Stream stopped for camera: {camera_id}")
                break
            except Exception as e:
                logger.error(f"Stream error: {e}")
                consecutive_failures += 1
                await asyncio.sleep(0.05)
        
        if consecutive_failures >= max_consecutive_failures:
            logger.warning(f"Repeated failures for camera: {camera_id}")
            
    except Exception as e:
        logger.error(f"General stream error: {e}")
    finally:
        if cap is not None:
            cap.release()
            logger.info(f"Camera connection closed: {camera_id}")


@router.get("/{camera_id}")
async def stream_video(camera_id: str, db: AsyncSession = Depends(get_db)):
    """
    Ø¨Ø« Ø§Ù„ÙÙŠØ¯ÙŠÙˆ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬ Ù…Ù† Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§
    
    ÙŠÙØ±Ø³Ù„ Ø¨Ø« MJPEG Ù„Ù„ÙÙŠØ¯ÙŠÙˆ Ù…Ø¹ Ù…Ø±Ø¨Ø¹Ø§Øª Ø§Ù„ÙƒØ´Ù
    
    - **camera_id**: Ù…Ø¹Ø±Ù Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§
    """
    logger.info(f"Starting stream for camera: {camera_id}")
    
    # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§
    result = await db.execute(
        select(Camera).where(Camera.id == camera_id)
    )
    camera = result.scalar_one_or_none()
    
    if not camera:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§ ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯Ø©"
        )
    
    if not camera.rtsp_url:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="Ø±Ø§Ø¨Ø· RTSP ØºÙŠØ± Ù…Ø­Ø¯Ø¯ Ù„Ù„ÙƒØ§Ù…ÙŠØ±Ø§"
        )
    
    # Ø¥Ø±Ø¬Ø§Ø¹ Ø¨Ø« Ø§Ù„ÙÙŠØ¯ÙŠÙˆ Ù…Ø¹ Ø§Ù„ÙƒØ´Ù
    return StreamingResponse(
        generate_video_frames_with_detection(
            camera_id, 
            camera.rtsp_url,
            detection_enabled=camera.detection_enabled
        ),
        media_type="multipart/x-mixed-replace; boundary=frame",
        headers={
            "Cache-Control": "no-cache, no-store, must-revalidate",
            "Pragma": "no-cache",
            "Expires": "0",
            "Connection": "keep-alive",
            "Access-Control-Allow-Origin": "*"
        }
    )


@router.get("/{camera_id}/snapshot")
async def get_snapshot(camera_id: str, db: AsyncSession = Depends(get_db)):
    """
    Ø¬Ù„Ø¨ Ù„Ù‚Ø·Ø© Ø­Ø§Ù„ÙŠØ© Ù…Ù† Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§
    
    ÙŠÙØ±Ø¬Ø¹ ØµÙˆØ±Ø© JPEG Ù„Ù„Ù‚Ø·Ø© Ø§Ù„Ø­Ø§Ù„ÙŠØ©
    
    - **camera_id**: Ù…Ø¹Ø±Ù Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§
    """
    logger.info(f"Getting snapshot from camera: {camera_id}")
    
    # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§
    result = await db.execute(
        select(Camera).where(Camera.id == camera_id)
    )
    camera = result.scalar_one_or_none()
    
    if not camera:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§ ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯Ø©"
        )
    
    if not camera.rtsp_url:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="Ø±Ø§Ø¨Ø· RTSP ØºÙŠØ± Ù…Ø­Ø¯Ø¯ Ù„Ù„ÙƒØ§Ù…ÙŠØ±Ø§"
        )
    
    # Ø¬Ù„Ø¨ Ù„Ù‚Ø·Ø© Ù…Ù† RTSP
    try:
        loop = asyncio.get_event_loop()
        
        def capture_snapshot():
            cap = cv2.VideoCapture(camera.rtsp_url, cv2.CAP_FFMPEG)
            cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)
            
            if not cap.isOpened():
                return None
            
            ret, frame = cap.read()
            cap.release()
            
            if not ret or frame is None:
                return None
            
            # âš¡ Ø§Ø³ØªØ®Ø¯Ø§Ù… TurboJPEG Ù„Ù„Ø³Ø±Ø¹Ø©
            return fast_encode_jpeg(frame, settings.JPEG_QUALITY_SNAPSHOT)
        
        image_bytes = await loop.run_in_executor(executor, capture_snapshot)
        
        if image_bytes is None:
            raise HTTPException(
                status_code=status.HTTP_503_SERVICE_UNAVAILABLE,
                detail="ÙØ´Ù„ ÙÙŠ Ø¬Ù„Ø¨ Ø§Ù„Ù„Ù‚Ø·Ø© Ù…Ù† Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§"
            )
        
        return Response(
            content=image_bytes,
            media_type="image/jpeg",
            headers={
                "Content-Disposition": f"inline; filename=snapshot_{camera_id}.jpg",
                "Cache-Control": "no-cache",
                "Access-Control-Allow-Origin": "*"
            }
        )
        
    except Exception as e:
        logger.error(f"Snapshot error: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Ø®Ø·Ø£ ÙÙŠ Ø¬Ù„Ø¨ Ø§Ù„Ù„Ù‚Ø·Ø©: {str(e)}"
        )


@router.get("/{camera_id}/snapshot-http")
async def get_snapshot_http(camera_id: str, db: AsyncSession = Depends(get_db)):
    """
    Ø¬Ù„Ø¨ Ù„Ù‚Ø·Ø© Ù…Ù† ÙƒØ§Ù…ÙŠØ±Ø§ HTTP (IP Webcam) Ø¹Ø¨Ø± HTTP Ù…Ø¨Ø§Ø´Ø±Ø©
    
    Ù‡Ø°Ø§ endpoint ÙŠØ¬Ù„Ø¨ Ø§Ù„ØµÙˆØ±Ø© Ù…Ù† Ø±Ø§Ø¨Ø· HTTP (/shot.jpg)
    Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† Ù…Ø­Ø§ÙˆÙ„Ø© ÙØªØ­ Ø¨Ø« RTSP/MJPEG
    
    Ù…ÙÙŠØ¯ Ù„Ù„ØªØºÙ„Ø¨ Ø¹Ù„Ù‰ Ù…Ø´ÙƒÙ„Ø© Docker networking
    """
    import httpx
    
    logger.info(f"Getting HTTP snapshot from camera: {camera_id}")
    
    # Ø¬Ù„Ø¨ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§
    result = await db.execute(
        select(Camera).where(Camera.id == camera_id)
    )
    camera = result.scalar_one_or_none()
    
    if not camera:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§ ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯Ø©"
        )
    
    if not camera.rtsp_url:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="Ø±Ø§Ø¨Ø· Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§ ØºÙŠØ± Ù…Ø­Ø¯Ø¯"
        )
    
    # Ø¨Ù†Ø§Ø¡ Ø±Ø§Ø¨Ø· Ø§Ù„Ù€ snapshot
    rtsp_url = camera.rtsp_url
    snapshot_url = None
    
    # Ù…Ø­Ø§ÙˆÙ„Ø© ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø±Ø§Ø¨Ø· Ø¥Ù„Ù‰ snapshot URL
    if "8080" in rtsp_url or "8081" in rtsp_url:  # IP Webcam
        # Ø§Ø³ØªØ¨Ø¯Ø§Ù„ /video Ø£Ùˆ /videofeed Ø¨Ù€ /shot.jpg
        base_url = rtsp_url.replace("/video", "").replace("/videofeed", "").rstrip("/")
        snapshot_url = f"{base_url}/shot.jpg"
        
        # Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø±Ø§Ø¨Ø· ÙŠØ´ÙŠØ± Ø¥Ù„Ù‰ IP Ù…Ø­Ù„ÙŠØŒ Ø­Ø§ÙˆÙ„ Ø§Ø³ØªØ®Ø¯Ø§Ù… host.docker.internal
        import re
        local_ip_match = re.search(r'http://192\.168\.\d+\.\d+', snapshot_url)
        if local_ip_match:
            # Ø¬Ø±Ù‘Ø¨ host.docker.internal Ø£ÙˆÙ„Ø§Ù‹
            docker_url = snapshot_url.replace(local_ip_match.group(), "http://host.docker.internal")
            try:
                async with httpx.AsyncClient(timeout=5.0) as client:
                    test_response = await client.head(docker_url)
                    if test_response.status_code == 200:
                        snapshot_url = docker_url
                        logger.info(f"Using host.docker.internal: {snapshot_url}")
            except:
                logger.info("host.docker.internal failed, trying original IP")
    
    if not snapshot_url:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="Ù„Ø§ ÙŠÙ…ÙƒÙ† ØªØ­Ø¯ÙŠØ¯ Ø±Ø§Ø¨Ø· Ø§Ù„Ù€ snapshot Ù„Ù‡Ø°Ø§ Ø§Ù„Ù†ÙˆØ¹ Ù…Ù† Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§Øª"
        )
    
    # Ø¬Ù„Ø¨ Ø§Ù„ØµÙˆØ±Ø©
    try:
        async with httpx.AsyncClient(timeout=10.0) as client:
            response = await client.get(snapshot_url)
            
            if response.status_code != 200:
                raise HTTPException(
                    status_code=status.HTTP_503_SERVICE_UNAVAILABLE,
                    detail=f"ÙØ´Ù„ Ø¬Ù„Ø¨ Ø§Ù„ØµÙˆØ±Ø©: HTTP {response.status_code}"
                )
            
            return Response(
                content=response.content,
                media_type="image/jpeg",
                headers={
                    "Content-Disposition": f"inline; filename=snapshot_{camera_id}.jpg",
                    "Cache-Control": "no-cache, no-store, must-revalidate",
                    "Access-Control-Allow-Origin": "*"
                }
            )
    except httpx.TimeoutException:
        raise HTTPException(
            status_code=status.HTTP_504_GATEWAY_TIMEOUT,
            detail="Ø§Ù†ØªÙ‡Ù‰ ÙˆÙ‚Øª Ø§Ù„Ø§Ù†ØªØ¸Ø§Ø± Ø£Ø«Ù†Ø§Ø¡ Ø¬Ù„Ø¨ Ø§Ù„ØµÙˆØ±Ø©"
        )
    except Exception as e:
        logger.error(f"HTTP snapshot error: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Ø®Ø·Ø£: {str(e)}"
        )


# =====================================
# Simulation Camera - ÙƒØ§Ù…ÙŠØ±Ø§ Ø§Ù„Ù…Ø­Ø§ÙƒØ§Ø©
# =====================================

import os
from pathlib import Path
from urllib.parse import quote

# Ù…Ø¬Ù„Ø¯ ÙÙŠØ¯ÙŠÙˆÙ‡Ø§Øª Ø§Ù„Ù…Ø­Ø§ÙƒØ§Ø©
SIMULATION_VIDEOS_DIR = Path(__file__).parent.parent.parent / "test_videos"
DEFAULT_SIMULATION_VIDEO = "pistol_video_simulation.mp4"


def _resolve_simulation_video(video: Optional[str]) -> Path:
    """
    Resolve and validate a simulation video filename inside SIMULATION_VIDEOS_DIR.
    Prevents path traversal; only allows existing .mp4 files in the directory.
    """
    filename = (video or DEFAULT_SIMULATION_VIDEO).strip()

    # Prevent traversal / nested paths
    if not filename or Path(filename).name != filename or any(sep in filename for sep in ("/", "\\")):
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="Ø§Ø³Ù… Ø§Ù„ÙÙŠØ¯ÙŠÙˆ ØºÙŠØ± ØµØ§Ù„Ø­"
        )

    if not filename.lower().endswith(".mp4"):
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="Ù†ÙˆØ¹ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ ØºÙŠØ± Ù…Ø¯Ø¹ÙˆÙ… (Ø§Ù„Ù…Ø·Ù„ÙˆØ¨ .mp4)"
        )

    video_path = (SIMULATION_VIDEOS_DIR / filename).resolve()
    try:
        video_path.relative_to(SIMULATION_VIDEOS_DIR.resolve())
    except Exception:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="Ø§Ø³Ù… Ø§Ù„ÙÙŠØ¯ÙŠÙˆ ØºÙŠØ± ØµØ§Ù„Ø­"
        )

    if not video_path.exists():
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail=f"Ù…Ù„Ù Ø§Ù„ÙÙŠØ¯ÙŠÙˆ ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯: {filename}"
        )

    return video_path


async def generate_simulation_frames(
    detection_enabled: bool = True,
    loop_video: bool = True,
    video_path: Optional[Path] = None,
    camera_id: str = "simulation",
) -> AsyncGenerator[bytes, None]:
    """
    Ù…ÙˆÙ„Ø¯ Ø¥Ø·Ø§Ø±Ø§Øª Ø§Ù„ÙÙŠØ¯ÙŠÙˆ Ù…Ù† Ù…Ù„Ù Ù…Ø­Ù„ÙŠ Ù„Ù„Ù…Ø­Ø§ÙƒØ§Ø©
    
    ÙŠÙØ±Ø¬Ø¹ Ø¥Ø·Ø§Ø±Ø§Øª MJPEG Ù„Ù„Ø¨Ø« Ù…Ø¹ Ù…Ø±Ø¨Ø¹Ø§Øª Ø§Ù„ÙƒØ´Ù
    Ø§Ù„ÙÙŠØ¯ÙŠÙˆ ÙŠØªÙƒØ±Ø± ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹ (loop)
    """
    cap = None
    frame_count = 0
    detection_interval = 5  # ØªØ´ØºÙŠÙ„ Ø§Ù„ÙƒØ´Ù ÙƒÙ„ 5 Ø¥Ø·Ø§Ø±Ø§Øª
    last_detections = []
    try:
        resolved_path = _resolve_simulation_video(video_path.name if video_path else None)
        video_path_str = str(resolved_path)
        
        if not os.path.exists(video_path_str):
            logger.error(f"Video file not found: {video_path_str}")
            return

        logger.info(f"Starting simulation from: {video_path_str} (camera_id={camera_id})")
        
        cap = cv2.VideoCapture(video_path_str)
        
        if not cap.isOpened():
            logger.error(f"Failed to open video file: {video_path}")
            return
        
        # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„ÙÙŠØ¯ÙŠÙˆ
        video_fps = cap.get(cv2.CAP_PROP_FPS) or 30
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        
        logger.info(f"Video opened: {video_fps} FPS, {total_frames} frames")
        
        loop = asyncio.get_event_loop()
        frame_interval = 1.0 / min(video_fps, 15)  # Ø­Ø¯ Ø£Ù‚ØµÙ‰ 15 FPS
        
        while True:
            try:
                ret, frame = cap.read()
                
                # Ø¥Ø°Ø§ Ø§Ù†ØªÙ‡Ù‰ Ø§Ù„ÙÙŠØ¯ÙŠÙˆØŒ Ø£Ø¹Ø¯ Ø§Ù„ØªØ´ØºÙŠÙ„
                if not ret or frame is None:
                    if loop_video:
                        cap.set(cv2.CAP_PROP_POS_FRAMES, 0)
                        # ğŸ”„ Ù…Ø³Ø­ Ø§Ù„ÙƒØ´ÙˆÙØ§Øª Ø§Ù„Ø³Ø§Ø¨Ù‚Ø© Ø¹Ù†Ø¯ Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„ØªØ´ØºÙŠÙ„
                        last_detections = []
                        # Ù…Ø³Ø­ motion cache Ù„Ù‡Ø°Ù‡ Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§
                        _motion_cache.pop(camera_id, None)
                        logger.info("Restarting video loop - cleared detections")
                        continue
                    else:
                        break
                
                # ØªØµØºÙŠØ± Ø§Ù„Ø¥Ø·Ø§Ø± Ù„ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø£Ø¯Ø§Ø¡
                height, width = frame.shape[:2]
                max_width = 640
                if width > max_width:
                    scale = max_width / width
                    frame = cv2.resize(frame, None, fx=scale, fy=scale)
                
                # ØªØ´ØºÙŠÙ„ Ø§Ù„ÙƒØ´Ù
                should_detect = detection_enabled and (frame_count % detection_interval == 0)
                
                if should_detect and detector.is_loaded:
                    try:
                        detections = []
                        results = detector.model(
                            frame,
                            conf=detector.confidence_threshold,
                            device=detector.device,
                            verbose=False
                        )
                        
                        for result in results:
                            boxes = result.boxes
                            if boxes is None or len(boxes) == 0:
                                continue
                            
                            all_xyxy = boxes.xyxy.cpu().numpy()
                            all_conf = boxes.conf.cpu().numpy()
                            all_cls = boxes.cls.cpu().numpy().astype(int)
                            
                            for i in range(len(boxes)):
                                x1, y1, x2, y2 = all_xyxy[i]
                                confidence = float(all_conf[i])
                                class_id = int(all_cls[i])
                                class_name = detector.model.names[class_id]
                                
                                detections.append({
                                    'class_name': class_name,
                                    'confidence': confidence,
                                    'bbox': (int(x1), int(y1), int(x2), int(y2))
                                })
                        
                        if detections:
                            last_detections = detections
                            logger.info(f"[Simulation] Detected {len(detections)} threat(s)")
                            
                            # ğŸš¨ Create alert for each detection
                            for det in detections:
                                # Determine camera name and location from camera_id
                                if "knife" in camera_id.lower():
                                    sim_camera_name = "ğŸ”ª Ù…Ø­Ø§ÙƒØ§Ø© Ø³ÙƒÙŠÙ†"
                                    sim_location = "ÙÙŠØ¯ÙŠÙˆ ØªØ¬Ø±ÙŠØ¨ÙŠ - Ø³ÙƒÙŠÙ†"
                                else:
                                    sim_camera_name = "ğŸ¬ ÙƒØ§Ù…ÙŠØ±Ø§ Ø§Ù„Ù…Ø­Ø§ÙƒØ§Ø©"
                                    sim_location = "ÙÙŠØ¯ÙŠÙˆ ØªØ¬Ø±ÙŠØ¨ÙŠ"
                                
                                # Create alert (async, non-blocking with rate limit)
                                asyncio.create_task(
                                    create_simulation_alert(
                                        camera_id=camera_id,
                                        camera_name=sim_camera_name,
                                        location=sim_location,
                                        detection=det,
                                        frame=frame.copy()
                                    )
                                )
                            
                    except Exception as e:
                        logger.error(f"Detection error: {e}")
                
                # Ø±Ø³Ù… Ø§Ù„Ù…Ø±Ø¨Ø¹Ø§Øª
                if last_detections:
                    frame = draw_detections_on_frame(frame, last_detections)
                
                # Ø¥Ø¶Ø§ÙØ© Ø¹Ù„Ø§Ù…Ø© Ø§Ù„Ù…Ø­Ø§ÙƒØ§Ø©
                cv2.putText(
                    frame, 
                    "SIMULATION", 
                    (10, 30), 
                    cv2.FONT_HERSHEY_SIMPLEX, 
                    1, 
                    (0, 255, 255), 
                    2
                )
                
                # ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ JPEG
                frame_bytes = fast_encode_jpeg(frame, settings.JPEG_QUALITY_STREAM)
                
                frame_count += 1
                
                yield (
                    b'--frame\r\n'
                    b'Content-Type: image/jpeg\r\n\r\n' + 
                    frame_bytes + 
                    b'\r\n'
                )
                
                await asyncio.sleep(frame_interval)
                
            except asyncio.CancelledError:
                logger.info("Simulation stopped")
                break
            except Exception as e:
                logger.error(f"Simulation error: {e}")
                await asyncio.sleep(0.1)
                
    except Exception as e:
        logger.error(f"General simulation error: {e}")
    finally:
        if cap is not None:
            cap.release()
            logger.info("Video file closed")


@router.get("/simulation/stream")
async def stream_simulation(detect: bool = True, video: Optional[str] = None):
    """
    ğŸ¬ Ø¨Ø« ÙÙŠØ¯ÙŠÙˆ Ù…Ø­Ø§ÙƒØ§Ø© Ù„Ù„Ø§Ø®ØªØ¨Ø§Ø±
    
    ÙŠØ³ØªØ®Ø¯Ù… Ù…Ù„Ù ÙÙŠØ¯ÙŠÙˆ Ù…Ø­Ù„ÙŠ ÙƒÙ…ØµØ¯Ø± Ù„Ù„Ø¨Ø« Ù…Ø¹ ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ÙƒØ´Ù Ø¹Ù† Ø§Ù„Ø£Ø³Ù„Ø­Ø©
    Ø§Ù„ÙÙŠØ¯ÙŠÙˆ ÙŠØªÙƒØ±Ø± ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹
    
    - **detect**: ØªÙØ¹ÙŠÙ„/ØªØ¹Ø·ÙŠÙ„ Ø§Ù„ÙƒØ´Ù (Ø§ÙØªØ±Ø§Ø¶ÙŠØ§Ù‹: Ù…ÙØ¹Ù‘Ù„)
    - **video**: Ø§Ø³Ù… Ù…Ù„Ù mp4 Ø¯Ø§Ø®Ù„ backend/test_videos (Ø§ÙØªØ±Ø§Ø¶ÙŠØ§Ù‹: ÙÙŠØ¯ÙŠÙˆ Ø§Ù„Ù…Ø­Ø§ÙƒØ§Ø© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ)
    """
    video_path = _resolve_simulation_video(video)
    camera_id = f"simulation:{video_path.name}"
    logger.info(
        f"Starting simulation stream - Detection: {'ON' if detect else 'OFF'} - Video: {video_path.name}"
    )
    
    return StreamingResponse(
        generate_simulation_frames(detection_enabled=detect, video_path=video_path, camera_id=camera_id),
        media_type="multipart/x-mixed-replace; boundary=frame",
        headers={
            "Cache-Control": "no-cache, no-store, must-revalidate",
            "Pragma": "no-cache",
            "Expires": "0",
            "Connection": "keep-alive",
            "Access-Control-Allow-Origin": "*"
        }
    )


@router.get("/simulation/videos")
async def list_simulation_videos():
    """
    Ù‚Ø§Ø¦Ù…Ø© ÙÙŠØ¯ÙŠÙˆÙ‡Ø§Øª Ø§Ù„Ù…Ø­Ø§ÙƒØ§Ø© Ø§Ù„Ù…ØªÙˆÙØ±Ø© Ø¯Ø§Ø®Ù„ backend/test_videos
    """
    if not SIMULATION_VIDEOS_DIR.exists():
        return {"available": False, "videos": []}

    videos = []
    for p in sorted(SIMULATION_VIDEOS_DIR.glob("*.mp4")):
        videos.append(
            {
                "filename": p.name,
                "is_default": p.name == DEFAULT_SIMULATION_VIDEO,
                "stream_url": f"/api/v1/stream/simulation/stream?video={quote(p.name)}",
            }
        )

    return {"available": len(videos) > 0, "videos": videos}


@router.get("/simulation/info")
async def get_simulation_info(video: Optional[str] = None):
    """
    Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¹Ù† ÙÙŠØ¯ÙŠÙˆ Ø§Ù„Ù…Ø­Ø§ÙƒØ§Ø©
    """
    try:
        video_path = _resolve_simulation_video(video)
    except HTTPException as e:
        return {"available": False, "message": e.detail}

    cap = cv2.VideoCapture(str(video_path))
    if not cap.isOpened():
        return {
            "available": False,
            "message": "ÙØ´Ù„ ÙØªØ­ Ù…Ù„Ù Ø§Ù„ÙÙŠØ¯ÙŠÙˆ"
        }
    
    fps = cap.get(cv2.CAP_PROP_FPS)
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    duration = total_frames / fps if fps > 0 else 0
    
    cap.release()
    
    return {
        "available": True,
        "filename": video_path.name,
        "resolution": f"{width}x{height}",
        "fps": fps,
        "duration_seconds": round(duration, 2),
        "total_frames": total_frames,
        "stream_url": f"/api/v1/stream/simulation/stream?video={quote(video_path.name)}"
    }


@router.get("/{camera_id}/info")
async def get_stream_info(camera_id: str, db: AsyncSession = Depends(get_db)):
    """
    Ø¬Ù„Ø¨ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø¨Ø«
    
    ÙŠÙØ±Ø¬Ø¹ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¹Ù† Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø¨Ø« Ù„Ù„ÙƒØ§Ù…ÙŠØ±Ø§
    
    - **camera_id**: Ù…Ø¹Ø±Ù Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§
    """
    logger.info(f"Getting stream info for camera: {camera_id}")
    
    result = await db.execute(
        select(Camera).where(Camera.id == camera_id)
    )
    camera = result.scalar_one_or_none()
    
    if not camera:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§ ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯Ø©"
        )
    
    return {
        "camera_id": camera.id,
        "camera_name": camera.name,
        "status": camera.status,
        "rtsp_url": camera.rtsp_url if camera.rtsp_url else None,
        "stream_quality": camera.stream_quality,
        "fps": camera.fps,
        "resolution": f"{settings.STREAM_WIDTH}x{settings.STREAM_HEIGHT}",
        "detection_enabled": camera.detection_enabled,
        "is_recording": camera.is_recording
    }


@router.get("/simulation/alerts/status")
async def get_simulation_alerts_status():
    """
    Ø­Ø§Ù„Ø© ØªÙ†Ø¨ÙŠÙ‡Ø§Øª Ø§Ù„Ù…Ø­Ø§ÙƒØ§Ø© Ù„ÙƒÙ„ ÙƒØ§Ù…ÙŠØ±Ø§
    """
    global _simulation_alert_cooldown, _simulation_alert_count
    
    status = {}
    for camera_id, count in _simulation_alert_count.items():
        last_alert = _simulation_alert_cooldown.get(camera_id, 0)
        time_since_last = time.time() - last_alert if last_alert > 0 else None
        
        status[camera_id] = {
            "alert_count": min(count, MAX_ALERTS_PER_CAMERA),
            "max_alerts": MAX_ALERTS_PER_CAMERA,
            "is_paused": count >= MAX_ALERTS_PER_CAMERA,
            "cooldown_seconds": SIMULATION_ALERT_INTERVAL,
            "time_since_last_alert": round(time_since_last, 1) if time_since_last else None,
            "can_alert": count < MAX_ALERTS_PER_CAMERA and (time_since_last is None or time_since_last >= SIMULATION_ALERT_INTERVAL)
        }
    
    return {
        "cameras": status,
        "settings": {
            "alert_interval_seconds": SIMULATION_ALERT_INTERVAL,
            "max_alerts_per_camera": MAX_ALERTS_PER_CAMERA
        }
    }


@router.post("/simulation/alerts/reset")
async def reset_simulation_alerts(camera_id: Optional[str] = None):
    """
    Ø¥Ø¹Ø§Ø¯Ø© ØªØ¹ÙŠÙŠÙ† Ø¹Ø¯Ø§Ø¯ ØªÙ†Ø¨ÙŠÙ‡Ø§Øª Ø§Ù„Ù…Ø­Ø§ÙƒØ§Ø©
    
    - Ø¥Ø°Ø§ ØªÙ… ØªØ­Ø¯ÙŠØ¯ camera_id: Ø¥Ø¹Ø§Ø¯Ø© ØªØ¹ÙŠÙŠÙ† Ù„ÙƒØ§Ù…ÙŠØ±Ø§ Ù…Ø­Ø¯Ø¯Ø©
    - Ø¥Ø°Ø§ Ù„Ù… ÙŠØªÙ… ØªØ­Ø¯ÙŠØ¯ camera_id: Ø¥Ø¹Ø§Ø¯Ø© ØªØ¹ÙŠÙŠÙ† Ù„Ø¬Ù…ÙŠØ¹ Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§Øª
    """
    global _simulation_alert_cooldown, _simulation_alert_count
    
    if camera_id:
        # Reset specific camera
        if camera_id in _simulation_alert_count:
            old_count = _simulation_alert_count[camera_id]
            _simulation_alert_count[camera_id] = 0
            _simulation_alert_cooldown[camera_id] = 0
            logger.info(f"ğŸ”„ Reset alerts for {camera_id}: {old_count} â†’ 0")
            return {"message": f"ØªÙ… Ø¥Ø¹Ø§Ø¯Ø© ØªØ¹ÙŠÙŠÙ† ØªÙ†Ø¨ÙŠÙ‡Ø§Øª {camera_id}", "reset_count": old_count}
        else:
            return {"message": f"Ù„Ø§ ØªÙˆØ¬Ø¯ ØªÙ†Ø¨ÙŠÙ‡Ø§Øª Ù„Ù€ {camera_id}", "reset_count": 0}
    else:
        # Reset all cameras
        total_reset = sum(_simulation_alert_count.values())
        _simulation_alert_count.clear()
        _simulation_alert_cooldown.clear()
        logger.info(f"ğŸ”„ Reset ALL simulation alerts: {total_reset} total")
        return {"message": "ØªÙ… Ø¥Ø¹Ø§Ø¯Ø© ØªØ¹ÙŠÙŠÙ† Ø¬Ù…ÙŠØ¹ ØªÙ†Ø¨ÙŠÙ‡Ø§Øª Ø§Ù„Ù…Ø­Ø§ÙƒØ§Ø©", "reset_count": total_reset}

"""
Ø®Ø¯Ù…Ø© Ø§Ù„ÙƒØ´Ù Ø¹Ù† Ø§Ù„Ø£Ø³Ù„Ø­Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… YOLO11
=====================================
Ø²Ù…Ù† Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø© Ø§Ù„Ù…Ø³ØªÙ‡Ø¯Ù: Ø£Ù‚Ù„ Ù…Ù† 2 Ø«Ø§Ù†ÙŠØ©
"""

import asyncio
import time
from typing import List, Dict, Optional, Tuple
from dataclasses import dataclass
import numpy as np
import cv2
from pathlib import Path

# Ø³ÙŠØªÙ… Ø§Ø³ØªÙŠØ±Ø§Ø¯Ù‡Ø§ Ø¹Ù†Ø¯ ØªØ«Ø¨ÙŠØª Ø§Ù„Ø­Ø²Ù…
try:
    from ultralytics import YOLO
except ImportError:
    YOLO = None

@dataclass
class Detection:
    """Ù†ØªÙŠØ¬Ø© ÙƒØ´Ù ÙˆØ§Ø­Ø¯Ø©"""
    id: str
    class_name: str
    confidence: float
    bbox: Tuple[int, int, int, int]  # x1, y1, x2, y2
    detection_type: str  # weapon, knife, suspicious_object

@dataclass
class DetectionResult:
    """Ù†ØªÙŠØ¬Ø© Ø§Ù„ÙƒØ´Ù Ø§Ù„ÙƒØ§Ù…Ù„Ø©"""
    frame_id: str
    timestamp: float
    detections: List[Detection]
    processing_time: float
    frame_with_boxes: Optional[np.ndarray] = None

class WeaponDetector:
    """Ù…Ø­Ø±Ùƒ Ø§Ù„ÙƒØ´Ù Ø¹Ù† Ø§Ù„Ø£Ø³Ù„Ø­Ø©"""
    
    # ØªØµÙ†ÙŠÙØ§Øª Ø§Ù„Ø£Ø³Ù„Ø­Ø©
    WEAPON_CLASSES = {
        'gun': 'weapon',
        'pistol': 'weapon',
        'rifle': 'weapon',
        'handgun': 'weapon',
        'knife': 'knife',
        'blade': 'knife',
        'sword': 'knife',
        'suspicious': 'suspicious_object'
    }
    
    # Ù…Ø³ØªÙˆÙŠØ§Øª Ø§Ù„Ø®Ø·ÙˆØ±Ø©
    SEVERITY_MAP = {
        'weapon': 'critical',
        'knife': 'high',
        'suspicious_object': 'medium'
    }
    
    def __init__(
        self,
        model_path: str = "./models/yolo11_weapons.pt",
        confidence_threshold: float = 0.7,
        device: str = "auto"
    ):
        """
        ØªÙ‡ÙŠØ¦Ø© Ù…Ø­Ø±Ùƒ Ø§Ù„ÙƒØ´Ù
        
        Args:
            model_path: Ù…Ø³Ø§Ø± Ù†Ù…ÙˆØ°Ø¬ YOLO
            confidence_threshold: Ø­Ø¯ Ø§Ù„Ø«Ù‚Ø© Ø§Ù„Ø£Ø¯Ù†Ù‰
            device: Ø§Ù„Ø¬Ù‡Ø§Ø² (cpu, cuda, mps, auto)
        """
        self.model_path = model_path
        self.confidence_threshold = confidence_threshold
        self.device = device
        self.model = None
        self.is_loaded = False
        
        # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø£Ø¯Ø§Ø¡
        self.total_detections = 0
        self.total_frames = 0
        self.average_time = 0.0
    
    async def load_model(self) -> bool:
        """ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬"""
        try:
            if YOLO is None:
                print("âš ï¸ Ù…ÙƒØªØ¨Ø© ultralytics ØºÙŠØ± Ù…Ø«Ø¨ØªØ©")
                return False
            
            model_file = Path(self.model_path)
            
            if not model_file.exists():
                print(f"âš ï¸ Ù…Ù„Ù Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯: {self.model_path}")
                print("ðŸ“¥ Ø³ÙŠØªÙ… Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù†Ù…ÙˆØ°Ø¬ YOLO Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠ Ù„Ù„ØªØ¬Ø±Ø¨Ø©")
                # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù†Ù…ÙˆØ°Ø¬ Ø¹Ø§Ù… Ù„Ù„ØªØ¬Ø±Ø¨Ø©
                self.model = YOLO("yolo11n.pt")
            else:
                self.model = YOLO(self.model_path)
            
            # ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø¬Ù‡Ø§Ø²
            if self.device == "auto":
                import torch
                if torch.cuda.is_available():
                    self.device = "cuda"
                elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
                    self.device = "mps"
                else:
                    self.device = "cpu"
            
            print(f"âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¹Ù„Ù‰: {self.device}")
            self.is_loaded = True
            return True
            
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬: {e}")
            return False
    
    async def detect(
        self,
        frame: np.ndarray,
        frame_id: str = "0"
    ) -> DetectionResult:
        """
        Ø§Ù„ÙƒØ´Ù Ø¹Ù„Ù‰ Ø¥Ø·Ø§Ø± ÙˆØ§Ø­Ø¯
        
        Args:
            frame: ØµÙˆØ±Ø© OpenCV (BGR)
            frame_id: Ù…Ø¹Ø±Ù Ø§Ù„Ø¥Ø·Ø§Ø±
            
        Returns:
            DetectionResult: Ù†ØªÙŠØ¬Ø© Ø§Ù„ÙƒØ´Ù
        """
        start_time = time.time()
        detections = []
        
        if not self.is_loaded or self.model is None:
            return DetectionResult(
                frame_id=frame_id,
                timestamp=time.time(),
                detections=[],
                processing_time=0.0
            )
        
        try:
            # ØªØ´ØºÙŠÙ„ Ø§Ù„ÙƒØ´Ù
            results = self.model(
                frame,
                conf=self.confidence_threshold,
                device=self.device,
                verbose=False
            )
            
            # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù†ØªØ§Ø¦Ø¬
            for result in results:
                boxes = result.boxes
                if boxes is None:
                    continue
                
                for i, box in enumerate(boxes):
                    # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
                    x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
                    confidence = float(box.conf[0])
                    class_id = int(box.cls[0])
                    class_name = self.model.names[class_id]
                    
                    # ØªØ­Ø¯ÙŠØ¯ Ù†ÙˆØ¹ Ø§Ù„ÙƒØ´Ù
                    detection_type = self._classify_detection(class_name)
                    
                    if detection_type:
                        detection = Detection(
                            id=f"{frame_id}_{i}",
                            class_name=class_name,
                            confidence=confidence,
                            bbox=(int(x1), int(y1), int(x2), int(y2)),
                            detection_type=detection_type
                        )
                        detections.append(detection)
            
            # Ø±Ø³Ù… Ø§Ù„ØµÙ†Ø§Ø¯ÙŠÙ‚ Ø¹Ù„Ù‰ Ø§Ù„Ø¥Ø·Ø§Ø±
            annotated_frame = self._draw_detections(frame.copy(), detections)
            
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ÙƒØ´Ù: {e}")
            annotated_frame = frame
        
        processing_time = time.time() - start_time
        
        # ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª
        self.total_frames += 1
        self.total_detections += len(detections)
        self.average_time = (
            (self.average_time * (self.total_frames - 1) + processing_time)
            / self.total_frames
        )
        
        return DetectionResult(
            frame_id=frame_id,
            timestamp=time.time(),
            detections=detections,
            processing_time=processing_time,
            frame_with_boxes=annotated_frame
        )
    
    def _classify_detection(self, class_name: str) -> Optional[str]:
        """ØªØµÙ†ÙŠÙ Ù†ÙˆØ¹ Ø§Ù„ÙƒØ´Ù"""
        class_lower = class_name.lower()
        
        for keyword, detection_type in self.WEAPON_CLASSES.items():
            if keyword in class_lower:
                return detection_type
        
        return None
    
    def _draw_detections(
        self,
        frame: np.ndarray,
        detections: List[Detection]
    ) -> np.ndarray:
        """Ø±Ø³Ù… ØµÙ†Ø§Ø¯ÙŠÙ‚ Ø§Ù„ÙƒØ´Ù Ø¹Ù„Ù‰ Ø§Ù„Ø¥Ø·Ø§Ø±"""
        
        colors = {
            'weapon': (0, 0, 255),      # Ø£Ø­Ù…Ø±
            'knife': (0, 165, 255),     # Ø¨Ø±ØªÙ‚Ø§Ù„ÙŠ
            'suspicious_object': (0, 255, 255)  # Ø£ØµÙØ±
        }
        
        for det in detections:
            x1, y1, x2, y2 = det.bbox
            color = colors.get(det.detection_type, (255, 255, 255))
            
            # Ø±Ø³Ù… Ø§Ù„ØµÙ†Ø¯ÙˆÙ‚
            cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)
            
            # Ø±Ø³Ù… Ø§Ù„Ù†Øµ
            label = f"{det.class_name}: {det.confidence:.2f}"
            label_size, _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 2)
            
            cv2.rectangle(
                frame,
                (x1, y1 - label_size[1] - 10),
                (x1 + label_size[0], y1),
                color,
                -1
            )
            cv2.putText(
                frame,
                label,
                (x1, y1 - 5),
                cv2.FONT_HERSHEY_SIMPLEX,
                0.5,
                (255, 255, 255),
                2
            )
        
        return frame
    
    def get_severity(self, detection_type: str) -> str:
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø®Ø·ÙˆØ±Ø©"""
        return self.SEVERITY_MAP.get(detection_type, 'low')
    
    def get_stats(self) -> Dict:
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø£Ø¯Ø§Ø¡"""
        return {
            "total_frames": self.total_frames,
            "total_detections": self.total_detections,
            "average_processing_time": self.average_time,
            "is_loaded": self.is_loaded,
            "device": self.device
        }

# Ù†Ø³Ø®Ø© Ø¹Ø§Ù…Ø© Ù„Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…
detector = WeaponDetector()
